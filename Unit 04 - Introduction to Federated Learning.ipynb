{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb1da77",
   "metadata": {},
   "source": [
    "# Federated Learning\n",
    "\n",
    "Federated learning is a machine learning paradigm that enables decentralized training of a shared model by multiple clients while preserving data privacy. The main idea behind this new paradigm is that each client trains a local model on its own data and then sends only the model updates to a central server, rather than sending the raw data. This allows the model to be trained on a large amount of data without compromising data privacy.\n",
    "\n",
    "Federated learning was first proposed by Google in 2016 (McMahan et al., 2016) and has since been applied in various fields, such as healthcare (Hard et al., 2018), finance (Yoon et al., 2018), and natural language processing (Li et al., 2020).For example, federated learning could be used to train a model that can make personalized recommendations for each user, without requiring the raw data from each user to be shared with a central server. This would enable the model to be trained on a large amount of data, while preserving data privacy.\n",
    "\n",
    "Federated learning has several key advantages over traditional centralized machine learning methods. First, it allows training on a much larger amount of data, as the data remains distributed across the clients. Second, it preserves data privacy by not requiring the raw data to be sent to the central server. And third, it enables collaboration among multiple clients, allowing them to jointly train a shared model without sharing their data.\n",
    "\n",
    "In the federated learning process, a central server sends a machine learning model to multiple devices. Each device trains the model on its local data, and then sends the updated model back to the central server. The central server aggregates the updates from each device and uses them to improve the global model. This process is repeated until the model has converged and can make accurate predictions on new data. Inside this process, main concepts are:\n",
    "\n",
    "* Client: a device or edge node that has a local dataset and participates in the training of the federated model\n",
    "* Server: a central server that coordinates the training of the federated model and receives the model updates from the clients\n",
    "* Federated dataset: the collection of decentralized datasets from different clients\n",
    "* Federated model: a machine learning model that is trained on the federated dataset using federated learning\n",
    "* Federated optimization: the process of training the federated model using the decentralized data and model updates from the clients.\n",
    "* Aggregation: the process to mixture the models based, for example, in a weighted average or an alternative approach.\n",
    "* Rounds: the times a federated model is distributed among Clients after performing an aggregation.\n",
    "\n",
    "It is a relatively new approach, therefore, there is no so many libraries that adapt it being the main actors: TensorFlow Federated, PySyft, OpenMined and Flower. Surely, one that has to be mentioned is TensorFlow Federated  although it is only a theoretical approach, becasuse nowadays it do not allow the deployment of the solution and only simulates the federated space. On the other hand, the Flower allows that distribution although the modifications a little more difficult. That is why the later has been chosen for this tutorial, due to a more gentle apporach and the possible use later. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf254d5",
   "metadata": {},
   "source": [
    "# Introduction to Flower (FLWR)\n",
    "\n",
    "It is a Python library that provides tools for implementing the comunications and coordinations of federated learning. It was designed to be easy to use and scalable. What Flower is not is a learning framework so, it is going to wrapped some others model such as Tensorflowm Pytorch or Scikit-learn ones in the comunications.\n",
    "\n",
    "To use Flower for federated learning, you will need to install the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2f2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flwr[simulation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82ce39",
   "metadata": {},
   "source": [
    "For a simulation environment it is better to execute the same comand but with the keyword *simulation* to ensure the load of the simulation environment. However, if you plan to used it distributedly, the line should be like `!pip install flwr` on both the server and the client devices. Once you have installed the `flwr` package, you can import it in your Python code using the following statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a157b7b",
   "metadata": {},
   "source": [
    "FLWR offers a number of classes and functions that you can use to set up a federated learning environment, train and evaluate a model, and implement regular updates to the model. For more information, you can refer to the FLWR [documentation](https://flower.dev/docs/quickstart-tensorflow.html). First we are going to define a model that can be used with the system. It shouuld be burn in mind that the mind has to be serializable to be able to go through the network. So, not models are going to be suitable for a federated learning apporach. For this example an Artificial Neural Netrwork (ANN) is going to be used based on Tensoflow and more specificly in Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model using TensorFlow\n",
    "def generate_ann():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167daad",
   "metadata": {},
   "source": [
    "So, due to the fact that we are going to use a Deep Learning model defined in Tensorfow, it is convinient to load the data in a `Dataset` class in order that the framework can deal with a possible hardware aceleration in GPU on the nodes. To do that, the following lines are going to load the MNIST dataset and generate a dataset with batches of 32 which, nowadays, could be run in most machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b84ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and partition the dataset that are present on each device\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(10000).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78c70c",
   "metadata": {},
   "source": [
    "Now let's introduce the two pieces of the puzzle, the `Client` and the `Server`. Flower would start a `Server`to coordinate the client devices and perform the orchestation of the model. The server interacts with clients through an interface called `Client`. When the server selects a particular client for training, it sends training instructions over the network. The client receives those instructions and calls one of the Client methods to run your code (i.e., to train the neural network we defined earlier).\n",
    "\n",
    "Flower provides a convenience class called NumPyClient which makes it easier to implement the Client interface when your workload uses Keras. The NumPyClient interface defines three methods which can be implemented in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a class to contain the details of the client and be the interface\n",
    "class MyClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, train_dataset, test_dataset):\n",
    "        self.net = generate_ann()\n",
    "        self.trainloader = train_dataset\n",
    "        self.valloader = test_datset\n",
    "    def get_parameters(self, config):\n",
    "        return model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        model.fit(self.trainloader, epochs=1, batch_size=32, steps_per_epoch=3)\n",
    "        return model.get_weights(), len(x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        loss, accuracy = model.evaluate(self.valloader)\n",
    "        return loss, len(x_test), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324ea6a",
   "metadata": {},
   "source": [
    "In the code above some points, we have defined the functions for the cliente that are required in this particular case.From this point, we can start a client with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the client\n",
    "fl.client.start_numpy_client(server_address=\"[::]:8080\", client=MyClient())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d96b24",
   "metadata": {},
   "source": [
    "The string `[::]:8080` tells the client which server to connect to. In this particular case, the code will be run in the same machine than the server. In case of a truly federated workload, all that needs to change is the server_address we point the client at.\n",
    "\n",
    "The another piece of the puzzle is the class that will contain the server this is going to be on a separate file for example `server.py`. The contend should be something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "\n",
    "fl.server.start_server(config=fl.server.ServerConfig(num_rounds=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684abf1",
   "metadata": {},
   "source": [
    " In this particular case, we can run two clients and a server in separated terminals of the machines. It should be as simple as in different terminal execute the commandline `python client.py` twice and `python server.py` once.\n",
    "\n",
    "In the server terminal we should receive an out put similar to: \n",
    "\n",
    "```shell\n",
    "INFO flower 2022-11-28 11:15:46,741 | app.py:76 | Flower server running (insecure, 3 rounds)\n",
    "INFO flower 2022-11-28 11:15:46,742 | server.py:72 | Getting initial parameters\n",
    "INFO flower 2022-11-28 11:16:01,770 | server.py:74 | Evaluating initial parameters\n",
    "INFO flower 2022-11-28 11:16:01,770 | server.py:87 | [TIME] FL starting\n",
    "DEBUG flower 2022-11-28 11:16:12,341 | server.py:165 | fit_round: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flower 2022-11-28 11:21:17,235 | server.py:177 | fit_round received 2 results and 0 failures\n",
    "DEBUG flower 2022-11-28 11:21:17,512 | server.py:139 | evaluate: strategy sampled 2 clients\n",
    "DEBUG flower 2022-11-28 11:21:29,628 | server.py:149 | evaluate received 2 results and 0 failures\n",
    "DEBUG flower 2022-11-28 11:21:29,696 | server.py:165 | fit_round: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flower 2022-11-28 11:25:59,917 | server.py:177 | fit_round received 2 results and 0 failures\n",
    "DEBUG flower 2022-11-28 11:26:00,227 | server.py:139 | evaluate: strategy sampled 2 clients\n",
    "DEBUG flower 2022-11-28 11:26:11,457 | server.py:149 | evaluate received 2 results and 0 failures\n",
    "DEBUG flower 2022-11-28 11:26:11,530 | server.py:165 | fit_round: strategy sampled 2 clients (out of 2)\n",
    "DEBUG flower 2022-11-28 11:30:43,389 | server.py:177 | fit_round received 2 results and 0 failures\n",
    "DEBUG flower 2022-11-28 11:30:43,630 | server.py:139 | evaluate: strategy sampled 2 clients\n",
    "DEBUG flower 2022-11-28 11:30:53,384 | server.py:149 | evaluate received 2 results and 0 failures\n",
    "INFO flower 2022-11-28 11:30:53,384 | server.py:122 | [TIME] FL finished in 891.6143046000007\n",
    "INFO flower 2022-11-28 11:30:53,385 | app.py:109 | app_fit: losses_distributed [(1, 2.3196680545806885), (2, 2.3202896118164062), (3, 2.1818180084228516)]\n",
    "INFO flower 2022-11-28 11:30:53,385 | app.py:110 | app_fit: accuracies_distributed []\n",
    "INFO flower 2022-11-28 11:30:53,385 | app.py:111 | app_fit: losses_centralized []\n",
    "INFO flower 2022-11-28 11:30:53,385 | app.py:112 | app_fit: accuracies_centralized []\n",
    "DEBUG flower 2022-11-28 11:30:53,442 | server.py:139 | evaluate: strategy sampled 2 clients\n",
    "DEBUG flower 2022-11-28 11:31:02,848 | server.py:149 | evaluate received 2 results and 0 failures\n",
    "INFO flower 2022-11-28 11:31:02,848 | app.py:121 | app_evaluate: federated loss: 2.1818180084228516\n",
    "INFO flower 2022-11-28 11:31:02,848 | app.py:125 | app_evaluate: results [('ipv4:127.0.0.1:31539', EvaluateRes(loss=2.1818180084228516, num_examples=10000, accuracy=0.0, metrics={'accuracy': 0.21610000729560852})), ('ipv4:127.0.0.1:31540', EvaluateRes(loss=2.1818180084228516, num_examples=10000, accuracy=0.0, metrics={'accuracy': 0.21610000729560852}))]\n",
    "INFO flower 2022-11-28 11:31:02,848 | app.py:127 | app_evaluate: failures [] flower 2020-11-18 11:07:56,396 | app.py:77 | app_evaluate: failures []\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8f5a6",
   "metadata": {},
   "source": [
    "With that, the first fererated approach is completed. As it can be seen the system goes through 3 rounds of fitting and evaluating in all clientes before the results are retived to the server aggregated and redistributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00137c",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Implement the Client and Server code on two separate files and compare the results with the ones here. Was your result similar?\n",
    "\n",
    "`Answer here`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf25335",
   "metadata": {},
   "source": [
    "# Updating parameters\n",
    "So, the key element in this kind of approach is the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data (which changes the model parameters locally) and sends the updated/changed model parameters back to the server (or, alternatively, it sends just the gradients back to the server, not the full model parameters).\n",
    "\n",
    "In `flwr`, this communications is basicly done by two helper functions to load and retrive the local parameters: `set_parameters` and `get_parameters`. This requirement blends extremely weel with non-state approaches such as **PyTorch** or **JAX**, although as it has been proof in the previous example can be also used with **Tensorflow** or, even, **scikit-learn**.\n",
    "\n",
    "Therefore, the basic structure for any client in this library has the same shape being:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467be0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader # Dataset for train\n",
    "        self.valloader = valloader # Dataset to validate\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net) # To be implemented specific for the framework\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters) # also to be implemented specificly for the framework\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508e352",
   "metadata": {},
   "source": [
    "In Flower, clients can be created by extending classes `lwr.client.Client` or `lwr.client.NumPyClient`. In this the previous example `NumPyClient` was used because it is easier to implement and requires less code as template. Apart from the extended class, three are the main methods to be implemented:\n",
    "\n",
    "* get_parameters: Return the current local model parameters\n",
    "\n",
    "* fit: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
    "\n",
    "* evaluate: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
    "\n",
    "As you can see, the `MyClient` class implemented in the previous example follows this very same structure.\n",
    "\n",
    "#### Be aware: \n",
    "Sometimes, specially when we are simulating several *Clients* in a single device, it could be usesful to use a function to create the client ehn it is required. This is particular important in stateless framework , such as PyTorch, which can make use of cleaper implementation that only create the clients when they are requiredd to train or evaluate. For example, the following code loads different examples for each client before discarting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eeb598",
   "metadata": {},
   "source": [
    "It might be notice that `myClient`can not be used in this same sense due to the state that it keeps internaly through the function `generate_ann`, however if it is taken out is can be sed in the same way.\n",
    "\n",
    "So, the clients are already setup to load, fit and evaluate, however, we lack how to integrate the results from the different clients. In Flower terms, it is what is called an Stategy, such as the *Federated Average (FedAvg)*. In a first approach we can use the built-in implementations of the framework, althouhg custom ones can also be used. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "        fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "        min_fit_clients=10,  # Never sample less than 10 clients for training\n",
    "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
    "        min_available_clients=10,  # Wait until all 10 clients are available\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8e116",
   "metadata": {},
   "source": [
    "This code would corresponds to the script running on the server and it uses the simulation function to test this kind of apporach in a single device with the precious optimization mentioned to not overload the device performing it. It tells the framework to generate 10 clients and randomly select all of them (`fraction_fit = 1.0`) and train the model on all of them.After receiving the updates from the clients, it perform the aggregation strategy before returning the global model to the clients for the next of the 5 rounds.\n",
    "\n",
    "One point to highlight is the fact that the framework si not only going to manage the `losses_distributed`, but none of the other metrics. Due to the diversity on the treatment of those measures, the framework cannot know authicaly  handle the aggregation of those metrics. Users need to tell the framework how to handle/aggregate these custom metrics. The strategy will then call these functions whenever it receives fit or evaluate metrics from clients. The two possible functions are `fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`. For example, the following code would create the average weightd and the previous example can be adapted as if follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=10,\n",
    "        min_evaluate_clients=5,\n",
    "        min_available_clients=10,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,  # put the metric aggregation for the evaluation\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7ba45",
   "metadata": {},
   "source": [
    "We will revisit the definition of custom strategies in the following Unit to define ourown to try to minimize some of the problems that federated learning has to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52ac8c",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Implement the simulation and test it with the CIFAR-10 dataset in a simulation environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Code to load the dataset\n",
    "def load_datasets(n_clients):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    cifar10 = tf.keras.datasets.cifar10\n",
    " \n",
    "    # Distribute it to train and test set\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    #Normalize data\n",
    "    #TODO\n",
    "    \n",
    "    #Prepare the datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "\n",
    "    # Split training set into 10 partitions to simulate the individual dataset\n",
    "    train_partition_size = len(x_train) // n_clients\n",
    "    test_partition_size = len(x_test) // n_clients\n",
    "    \n",
    "    #Randomize the datasets\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(10_000)\n",
    "    test_dataset = train_dataset.shuffle(2_000)\n",
    "\n",
    "    # Split each partition \n",
    "    train_ds = []\n",
    "    test_ds = []\n",
    "    for _ in range(n_clients):\n",
    "        train_ds.append(train_dataset.take(train_partition_size))    \n",
    "        train_dataset = train_dataset.skip(train_partition_size)\n",
    "        test_ds.append(test_dataset.take(test_partition_size))\n",
    "        test_dataset = test_dataset.skip(test_partition_size)\n",
    "\n",
    "train_ds, test_ds = load_datasets()\n",
    "\n",
    "#TODO Client, client_fn and simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b411f",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "In order to close this lesson, lets take a closer look to the key point of those strategies, i. e., the aggregation algorithm. These are the ones responsable to combine the updates from the clients in order to generate the global model and they are defined in the Strategies as we have seen. Generally speaking, there are several  types of aggregation that can be used in federated learning (Reddi et. el, 2020), including:\n",
    "\n",
    "* Federated averaging (`flwr.server.strategy.FedAvg`): In this approach, each device computes an update to the model parameters based on its local data, and these updates are then averaged together to create the global model. This approach is simple and effective, but it can be sensitive to the size of the updates and the quality of the data on each device.\n",
    "\n",
    "* Federated weighted averaging: This approach is similar to federated averaging, but each device's update is given a different weight based on the size of its data set or the quality of its data. This can help to give more influence to devices with larger or higher-quality data.\n",
    "\n",
    "* Federated averaging with momentum (`flwr.server.strategy.FedAvgM`): This approach is similar to federated averaging, but it incorporates a momentum term in order to smooth out the updates and help the model converge more quickly.\n",
    "\n",
    "* Federated stochastic gradient descent(`flwr.server.strategy.FedAdagrad`): In this approach, each device computes an update to the model parameters based on a small batch of its local data, rather than the entire data set. This can help to reduce the communication overhead and improve the convergence rate of the model.\n",
    "\n",
    "* Federated ADAM (`flwr.server.strategy.FedAdam`): This approach is a variant of federated stochastic gradient descent that uses the ADAM optimization algorithm to adaptively adjust the learning rate based on the gradient and second moment estimates.\n",
    "\n",
    "All the previous ones are implemented, with the exception of Federated weigthed averaging, are implemented in the framework and can be use through the different stratefies together with other more uncommon. The choice of aggregation method will depend on the specific characteristics of the data and the requirements of the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1fc5f",
   "metadata": {},
   "source": [
    "#### References\n",
    "* Hard, A., Konečný, J., McMahan, H. B., Richemond-Barakat, C., Sivek, J. S., & Talwar, K. (2018). Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1812.02903.\n",
    "* Li, Y., Bonawitz, K., & Talwar, K. (2020). Fedprox: An optimizer for communication-efficient federated learning. arXiv preprint arXiv:2002.04283.\n",
    "* McMahan, H. B., Moore, E., Ramage, D., Hampson, S., & y Arcas, B. A. (2016). Communication-efficient learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629.\n",
    "* Yoon, J., Hard, A., Konečný, J., McMahan, H. B., & Sohl-Dickstein, J. (2018). Federal regression: A simple and scalable method for heterogeneous federated learning. arXiv preprint arXiv:1812.03862.\n",
    "* Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Konečný, J., Kumar, S. and McMahan, H.B., 2020. Adaptive federated optimization. arXiv preprint arXiv:2003.00295."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f6d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
