{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c81d538",
   "metadata": {},
   "source": [
    "# Stream Learning\n",
    "\n",
    " Most human activity has time as a key feature related to them. That relationship can be described according to the scale as a short-term or a long-term one. For example, a short-term relationship could be the recording of a signal for some time before analysing or processing it. Based on the features that could the extraction from a sliding window, machine learning approaches would usually build up a dataset for training and testing. That dataset would have several sections of the signal with the corresponding desired output for that piece of information. However, this is more complicated with long-term relationships that could not be easily recorded due to the scale. In this case, the evolution of the input does not show on the signal by itself making it much harder to capture those changes. Usually, classical machine learning approaches have struggled to keep the pace of the latter type. The common approach to tackle this kind of issue is to retrain a model from time to time and deploy an update, sometimes with a difference of minutes or even seconds. Alternatively, to deal with this kind of problem, a new knowledge area inside machine learning has arisen called online learning or stream learning.\n",
    "\n",
    "Nowadays, due to possible confusion with some teaching practices, the term online learning has been replaced by stream learning. This term designates a specific scenario for an intelligent model, one where the model is constantly fed with an infinite stream of data. Therefore, instead of a stable dataset which is fed once and again to adjust the model, the model is only to see that data once. This slight change comes with not a few issues that have to be tackled. Additionally, this approach also comes with new opportunities that are going to be covered in the following sections as long as the problems.\n",
    "\n",
    "However, before starting, it is required to formally define some background concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9fb515",
   "metadata": {},
   "source": [
    "## Data Stream\n",
    "\n",
    "First and foremost, a key definition which is at the very core of stream learning is the term data stream. This term refers to a sequential collection of individual elements which, when we are talking about a machine learning approach, is a set of features measured simultaneously on an entity.\n",
    "\n",
    "Each set of features measured at a certain time is also referred to as an observation or sample. At this point, It might be worth mentioning that those samples can have a stable structure, e.g., in every sample, all features are measured, or it can be more flexible with features that appear and disappear over time.\n",
    "\n",
    "Therefore, generally speaking, we understand a data stream as a continuous set of samples over time.\n",
    "\n",
    "\n",
    "### Reactive and proactive data streams\n",
    "\n",
    "Those data streams can be later classified depending on the relationship with the user in reactive and proactive.\n",
    "\n",
    "Reactive data streams are ones where the data comes to you. Typical examples can be the visits to a website, the interactions with a server, the events on a machine, etc. Therefore, any data stream that's out of your control and over which, you have no influence or control further than receiving and reading it. It just happens and you have to react to it.\n",
    "\n",
    "Proactive data streams are ones where you have control over the data stream. For example, you might be reading the data from a file. You decide at which speed you want to read the data, in what order, etc.\n",
    "\n",
    "\n",
    "## Online processing\n",
    "This concept refers to processing a stream of data observation by observation. More specifically, if we focus on machine learning, it refers to training a model by teaching it one sample at a time.\n",
    "\n",
    "This concept makes stream learning the complete opposite of the traditional approach, where the samples are packed in batches and, then, adjust the model after processing the errors of the bunch. Therefore, in online processing, the vectorization doesn't bring any speedup and numeric processing libraries such as NumPy and PyTorch bring too much overhead. So, the new approach does not revisit past data as the batched approach does, because it has a continuous data stream which, usually, can only be seen by the model once.\n",
    "\n",
    "So, this concept establishes one of the key points of this approach and it is that the online learning model is a stateful, dynamic object. Consequently, we are in front of a new machine-learning paradigm with its pros and cons.\n",
    "\n",
    "## Datasets in training\n",
    "\n",
    "Although in production, 90% of the data stream is going to be reactive, when we have to tackle the training and evaluation of a model a dataset is usually built. The reason behind this is that we usually do not have access to the real-time feed when we are developing the model, so it has to be simulated with some captured observations.\n",
    "\n",
    "However, the capture of the dataset ends the similarities between traditional machine learning and online machine learning. Opposite to the first one, the online approach does not split the data into training and evaluation datasets but uses the whole dataset in both stages. So, when an observation arrives, it is used to evaluate the model and later the model is adjusted according to the output. This pace is continuously used in this kind of model and it is especially important for the time component to know which element comes first of which. The idea is to simulate the same scenario that the model is going to find in the real life to ensure correct behaviour over time.\n",
    "\n",
    "\n",
    "### Concept Drift\n",
    "\n",
    "The main reason why any machine learning approach, offline or online, can not be performing well with this kind of problem with a continuous feed of data is the concept drift. By this term, researchers named the situation when the data start to change over time a pattern not previously noticed appears or the balance among classes can vary.\n",
    "\n",
    "The advantage of online models is that they can keep learning and, consequently, they can cope with drift. So, this kind of approach can adapt to concept drift seamlessly without having to retrain a new model. We would revisit this concept later with an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f324f102",
   "metadata": {},
   "source": [
    "# Stream Machine Learning Libraries\n",
    "\n",
    "Due to being a relatively new apporach, stream learning do not have a lot of implementations nowadays. In fact, the usual approach are ad-hoc implementations for each particular problem and entity. It has not been until recently that some libraries has appear in the stage with a more general approach to this point of view. The main actors nowadays can be resumed as:\n",
    "\n",
    "- **[Apache SAMOA](https://incubator.apache.org/projects/samoa.html)**, a project to perform anÃ¡lisis and data mining on data Streams. It has a part focused on machine learning. Do not recive any update since 2020 and it is still in the incubator of the Apache Fundation. It is roumored that the foundation is going to drop its development.\n",
    "\n",
    "- **[MOA](https://moa.cms.waikato.ac.nz/)**, the name comes from Massive Online Analysis. This proyect has been developed by the same authors of the WEKA proyect. So, it is deeply related with this one and it has been also written in Java. It includes a collection of machine learning algorithms (classification, regression, clustering, outlier detection, concept drift detection and recommender systems) and tools for evaluation. It is mainly limited to the interface provided or to implement extensions if you want to work with the remaining ecosystem.\n",
    "\n",
    "- **[Vowpal wabbit](https://vowpalwabbit.org/)**, a Python library with a more general approach which cover questions like reinforment learning. It has a section focused on steam learning but more from the point of view reiforment learning. It has as downsize the requirement of a particular format in the data for the library, which significantl affects it s performance and usability\n",
    "\n",
    "- **[River](https://riverml.xyz/)**, another Python library focused on stream learning which has a more general appoach than Vowpal Wabbit. In this case the number of models is similar to the ones present in scikit-learn with the tools to adapt them to the new approach. Additionaly it also has the possibility to develop reinforment learning approaches. As main advantage, it can work with the most common types of data such as Pandas Dataframes.\n",
    "\n",
    "In this subject,  River is going to be our reference implementation in order to widen the number of problems that we can tackle with. Let's see a couple of examples for the most common scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a5777",
   "metadata": {},
   "source": [
    "## Binary classisification\n",
    "\n",
    "Probably the most elemental approach to machine learning in general. In this case the models have a single output which is going to tell as if an example is from a certain class or the complementary one.\n",
    "\n",
    "1. First step should be to install the library if we haven't done it, yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e7893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It would required to use a version of Python >3.8\n",
    "try:\n",
    "    import river\n",
    "except ImportError as err:\n",
    "    !pip install river\n",
    "\n",
    "    \n",
    "# this library is only to improve the redability of some structures\n",
    "# https://rich.readthedocs.io/en/stable/introduction.html\n",
    "try:\n",
    "    from rich import print\n",
    "except ImportError as err:\n",
    "    !pip install rich\n",
    "    from rich import print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288d5f7",
   "metadata": {},
   "source": [
    "2. Import a dataset to operate with. In this case the problem is going to be a detector of bank fraud with credit cards, one of the example dataset that river has implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe4cc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The object contains the information of the dataset, such as, number of samples and features\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The object contains the information of the dataset, such as, number of samples and features\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Credit card frauds.\n",
       "\n",
       "The datasets contains transactions made by credit cards in September <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2013</span> by european\n",
       "cardholders. This dataset presents transactions that occurred in two days, where we have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">492</span>\n",
       "frauds out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">807</span> transactions. The dataset is highly unbalanced, the positive class\n",
       "<span style=\"font-weight: bold\">(</span>frauds<span style=\"font-weight: bold\">)</span> account for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.172</span>% of all transactions.\n",
       "\n",
       "It contains only numerical input variables which are the result of a PCA transformation.\n",
       "Unfortunately, due to confidentiality issues, we cannot provide the original features and more\n",
       "background information about the data. Features V1, V2, <span style=\"color: #808000; text-decoration-color: #808000\">...</span> V28 are the principal components\n",
       "obtained with PCA, the only features which have not been transformed with PCA are <span style=\"color: #008000; text-decoration-color: #008000\">'Time'</span> and\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Amount'</span>. Feature <span style=\"color: #008000; text-decoration-color: #008000\">'Time'</span> contains the seconds elapsed between each transaction and the first\n",
       "transaction in the dataset. The feature <span style=\"color: #008000; text-decoration-color: #008000\">'Amount'</span> is the transaction Amount, this feature can be\n",
       "used for example-dependant cost-senstive learning. Feature <span style=\"color: #008000; text-decoration-color: #008000\">'Class'</span> is the response variable and\n",
       "it takes value <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> in case of fraud and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> otherwise.\n",
       "\n",
       "      Name  CreditCard                                                     \n",
       "      Task  Binary classification                                          \n",
       "   Samples  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">807</span>                                                        \n",
       "  Features  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>                                                             \n",
       "    Sparse  <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                                                          \n",
       "      Path  <span style=\"color: #800080; text-decoration-color: #800080\">/home/david/river_data/CreditCard/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">creditcard.csv</span>               \n",
       "       URL  <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://maxhalford.github.io/files/datasets/creditcardfraud.zip</span>\n",
       "      Size  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">143.84</span> MB                                                      \n",
       "Downloaded  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Credit card frauds.\n",
       "\n",
       "The datasets contains transactions made by credit cards in September \u001b[1;36m2013\u001b[0m by european\n",
       "cardholders. This dataset presents transactions that occurred in two days, where we have \u001b[1;36m492\u001b[0m\n",
       "frauds out of \u001b[1;36m284\u001b[0m,\u001b[1;36m807\u001b[0m transactions. The dataset is highly unbalanced, the positive class\n",
       "\u001b[1m(\u001b[0mfrauds\u001b[1m)\u001b[0m account for \u001b[1;36m0.172\u001b[0m% of all transactions.\n",
       "\n",
       "It contains only numerical input variables which are the result of a PCA transformation.\n",
       "Unfortunately, due to confidentiality issues, we cannot provide the original features and more\n",
       "background information about the data. Features V1, V2, \u001b[33m...\u001b[0m V28 are the principal components\n",
       "obtained with PCA, the only features which have not been transformed with PCA are \u001b[32m'Time'\u001b[0m and\n",
       "\u001b[32m'Amount'\u001b[0m. Feature \u001b[32m'Time'\u001b[0m contains the seconds elapsed between each transaction and the first\n",
       "transaction in the dataset. The feature \u001b[32m'Amount'\u001b[0m is the transaction Amount, this feature can be\n",
       "used for example-dependant cost-senstive learning. Feature \u001b[32m'Class'\u001b[0m is the response variable and\n",
       "it takes value \u001b[1;36m1\u001b[0m in case of fraud and \u001b[1;36m0\u001b[0m otherwise.\n",
       "\n",
       "      Name  CreditCard                                                     \n",
       "      Task  Binary classification                                          \n",
       "   Samples  \u001b[1;36m284\u001b[0m,\u001b[1;36m807\u001b[0m                                                        \n",
       "  Features  \u001b[1;36m30\u001b[0m                                                             \n",
       "    Sparse  \u001b[3;91mFalse\u001b[0m                                                          \n",
       "      Path  \u001b[35m/home/david/river_data/CreditCard/\u001b[0m\u001b[95mcreditcard.csv\u001b[0m               \n",
       "       URL  \u001b[4;94mhttps://maxhalford.github.io/files/datasets/creditcardfraud.zip\u001b[0m\n",
       "      Size  \u001b[1;36m143.84\u001b[0m MB                                                      \n",
       "Downloaded  \u001b[3;92mTrue\u001b[0m                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "from river import datasets\n",
    "\n",
    "dataset = datasets.CreditCard()\n",
    "print(f\"The object contains the information of the dataset, such as, number of samples and features\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6f5822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3598071336738</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0727811733098497</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V3'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.53634673796914</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V4'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.37815522427443</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V5'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.338320769942518</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V6'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.462387777762292</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V7'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.239598554061257</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V8'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0986979012610507</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V9'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.363786969611213</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V10'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0907941719789316</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V11'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.551599533260813</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V12'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.617800855762348</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V13'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.991389847235408</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V14'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.311169353699879</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V15'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.46817697209427</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V16'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.470400525259478</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V17'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.207971241929242</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V18'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0257905801985591</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V19'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.403992960255733</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V20'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.251412098239705</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V21'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.018306777944153</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V22'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.277837575558899</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V23'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.110473910188767</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V24'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0669280749146731</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V25'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.128539358273528</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V26'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.189114843888824</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V27'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.133558376740387</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'V28'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0210530534538215</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Amount'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">149.62</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'Time'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'V1'\u001b[0m: \u001b[1;36m-1.3598071336738\u001b[0m,\n",
       "    \u001b[32m'V2'\u001b[0m: \u001b[1;36m-0.0727811733098497\u001b[0m,\n",
       "    \u001b[32m'V3'\u001b[0m: \u001b[1;36m2.53634673796914\u001b[0m,\n",
       "    \u001b[32m'V4'\u001b[0m: \u001b[1;36m1.37815522427443\u001b[0m,\n",
       "    \u001b[32m'V5'\u001b[0m: \u001b[1;36m-0.338320769942518\u001b[0m,\n",
       "    \u001b[32m'V6'\u001b[0m: \u001b[1;36m0.462387777762292\u001b[0m,\n",
       "    \u001b[32m'V7'\u001b[0m: \u001b[1;36m0.239598554061257\u001b[0m,\n",
       "    \u001b[32m'V8'\u001b[0m: \u001b[1;36m0.0986979012610507\u001b[0m,\n",
       "    \u001b[32m'V9'\u001b[0m: \u001b[1;36m0.363786969611213\u001b[0m,\n",
       "    \u001b[32m'V10'\u001b[0m: \u001b[1;36m0.0907941719789316\u001b[0m,\n",
       "    \u001b[32m'V11'\u001b[0m: \u001b[1;36m-0.551599533260813\u001b[0m,\n",
       "    \u001b[32m'V12'\u001b[0m: \u001b[1;36m-0.617800855762348\u001b[0m,\n",
       "    \u001b[32m'V13'\u001b[0m: \u001b[1;36m-0.991389847235408\u001b[0m,\n",
       "    \u001b[32m'V14'\u001b[0m: \u001b[1;36m-0.311169353699879\u001b[0m,\n",
       "    \u001b[32m'V15'\u001b[0m: \u001b[1;36m1.46817697209427\u001b[0m,\n",
       "    \u001b[32m'V16'\u001b[0m: \u001b[1;36m-0.470400525259478\u001b[0m,\n",
       "    \u001b[32m'V17'\u001b[0m: \u001b[1;36m0.207971241929242\u001b[0m,\n",
       "    \u001b[32m'V18'\u001b[0m: \u001b[1;36m0.0257905801985591\u001b[0m,\n",
       "    \u001b[32m'V19'\u001b[0m: \u001b[1;36m0.403992960255733\u001b[0m,\n",
       "    \u001b[32m'V20'\u001b[0m: \u001b[1;36m0.251412098239705\u001b[0m,\n",
       "    \u001b[32m'V21'\u001b[0m: \u001b[1;36m-0.018306777944153\u001b[0m,\n",
       "    \u001b[32m'V22'\u001b[0m: \u001b[1;36m0.277837575558899\u001b[0m,\n",
       "    \u001b[32m'V23'\u001b[0m: \u001b[1;36m-0.110473910188767\u001b[0m,\n",
       "    \u001b[32m'V24'\u001b[0m: \u001b[1;36m0.0669280749146731\u001b[0m,\n",
       "    \u001b[32m'V25'\u001b[0m: \u001b[1;36m0.128539358273528\u001b[0m,\n",
       "    \u001b[32m'V26'\u001b[0m: \u001b[1;36m-0.189114843888824\u001b[0m,\n",
       "    \u001b[32m'V27'\u001b[0m: \u001b[1;36m0.133558376740387\u001b[0m,\n",
       "    \u001b[32m'V28'\u001b[0m: \u001b[1;36m-0.0210530534538215\u001b[0m,\n",
       "    \u001b[32m'Amount'\u001b[0m: \u001b[1;36m149.62\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look on the first example\n",
    "sample, target = next(iter(dataset))\n",
    "print(sample)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8d48a",
   "metadata": {},
   "source": [
    "Working with imbalanced classes is quite usual in online learning for tasks such as fraud detection and spam classification. The CreditCard dataset is certainly inbalanted and it provide us information about its classes in the description. However, we can easily calculate this percentages of representation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad47bcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284315</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.83</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0\u001b[0m: \u001b[1;36m284315\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m99.83\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">492</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m: \u001b[1;36m492\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m0.17\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections #python library\n",
    "\n",
    "counts = collections.Counter(target for _, target in dataset)#it generates a dictionary with labels and counts\n",
    "\n",
    "for label, count in counts.items():\n",
    "    print(f'{label}: {count} ({count / sum(counts.values()):.2%})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4bf02",
   "metadata": {},
   "source": [
    "In this baseline example we are not working  with the imbalanced problem. However, there are different approaches to deal with it in order to improve the ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31abb124",
   "metadata": {},
   "source": [
    "3. Build a model that can be used to discriminate between the two classes. In this particular case, a very simple linear_model ([logisticRegression](https://riverml.xyz/0.14.0/api/linear-model/LogisticRegression/)) is going to be created in order to exemplify a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d22f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c1fe5",
   "metadata": {},
   "source": [
    "Without properly training the model, the result of the probabilities for each class is exactly the same as it can be seen on the call to function `predict_proba_one`. Let's see which response we have with the previous `sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0fb760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[3;91mFalse\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[3;92mTrue\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.predict_proba_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66530209",
   "metadata": {},
   "source": [
    "So, for each class we have a random classifier with no knowledge. This is the point were things differ from traditional machine learning. The same sample that has been used to test, it is going to be used to adjust the model, because that sample is no longer available. Any kind of performance metric must be calculated before adjusting the model.\n",
    "\n",
    "4. Train the model with the tested sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd06764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.learn_one(sample, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c33ac",
   "metadata": {},
   "source": [
    "If we test again with the same pattern we would see variation of the probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153346d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[3;91mFalse\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[3;92mTrue\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.predict_proba_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70980bd",
   "metadata": {},
   "source": [
    "Simply to test the output and get an answer we can execute <code>predict_one()</code>, that returns the class label without probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82663a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.predict_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ceef8",
   "metadata": {},
   "source": [
    "To integrate the steps in a single loop and see a complete process, the following piece of code shows how to use a loop and how integrate a rolling measure for this kind of systems. There are different available metrics in River. In this particular case  the Area under the [ROC curve](https://riverml.xyz/0.14.0/api/metrics/ROCAUC/) is used, but we could have selected any other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234e347c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ROCAUC: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.87</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ROCAUC: \u001b[1;36m52.87\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "for sample, target in dataset:\n",
    "    prediction = model.predict_one(sample)\n",
    "    metric.update(target, prediction)\n",
    "    model.learn_one(sample, target)\n",
    "   \n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5910867",
   "metadata": {},
   "source": [
    "A common and simple approach to improve the model performance is to scale the data. There are different preprocessing operations available in River including methods for scaling data. One approach is the data standarization using the [preprocessing.StandardScaler](https://riverml.xyz/0.14.0/api/preprocessing/StandardScaler/). \n",
    "\n",
    "It should be highlighted, that not only models can be used in a similar way to `scikit-learn`, but the library also has pipelines in their core to link different processes. For example, here is a pipeline with two operators: StandarScaler and LogisticRegression. In this case, it could be worth mentioning, we haven't use the loop because there is a function that makes the loop and evaluation for us, i.e., `evaluate. progressive_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d9503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StandardScaler | LogisticRegression\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StandardScaler | LogisticRegression\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ROCAUC: 89.11%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import evaluate\n",
    "from river import compose\n",
    "from river import preprocessing\n",
    "\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "evaluate.progressive_val_score(dataset, model, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcae40f",
   "metadata": {},
   "source": [
    "## Multiclass Classification\n",
    "\n",
    "The next step in complexity should be the multiclass classification, where each instance, instead of a single two-class problem, can belong to any of a set of labels. In this scenario, the steps are similar to the binary classification but adapting the techniques or the loss functions to take into account the multioutput. For example, using the same library as before, we use a dataset with different images to identify the type of elements which could belong to any of  7 possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeaf3b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Image segments classification.\n",
       "\n",
       "This dataset contains features that describe image segments into <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> classes: brickface, sky,\n",
       "foliage, cement, window, path, and grass.\n",
       "\n",
       "    Name  ImageSegments                                                                                      \n",
       "    Task  Multi-class classification                                                                         \n",
       " Samples  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">310</span>                                                                                              \n",
       "Features  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>                                                                                                 \n",
       "  Sparse  <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                                                                                              \n",
       "    Path  <span style=\"color: #800080; text-decoration-color: #800080\">/home/david/software/miniconda3/envs/ml2/lib/python3.8/site-packages/river/datasets/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">segment.csv.zip</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Image segments classification.\n",
       "\n",
       "This dataset contains features that describe image segments into \u001b[1;36m7\u001b[0m classes: brickface, sky,\n",
       "foliage, cement, window, path, and grass.\n",
       "\n",
       "    Name  ImageSegments                                                                                      \n",
       "    Task  Multi-class classification                                                                         \n",
       " Samples  \u001b[1;36m2\u001b[0m,\u001b[1;36m310\u001b[0m                                                                                              \n",
       "Features  \u001b[1;36m18\u001b[0m                                                                                                 \n",
       "  Sparse  \u001b[3;91mFalse\u001b[0m                                                                                              \n",
       "    Path  \u001b[35m/home/david/software/miniconda3/envs/ml2/lib/python3.8/site-packages/river/datasets/\u001b[0m\u001b[95msegment.csv.zip\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "from river import datasets\n",
    "\n",
    "dataset = datasets.ImageSegments()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376c72e",
   "metadata": {},
   "source": [
    "As in binary classification, the dataset has the samples associated with a particular target in a tuple-like structure. However, it is here where we can see the first difference with the binary classifier. In this case, we are going to define a new classification method called the [Hoeffding tree](https://riverml.xyz/0.14.0/api/tree/HoeffdingTreeClassifier/). When the probabilities are checked  for a certain sample (<code>predict_proba_one</code>), it is going to be empty. The reason is that the model has not already seen any sample. So, it has no information about the \"possible\" classes. If this were a binary classifier, it would output a probability of 50% for True and False because the classes would be implicit. But in this case, we're doing multiclass classification.\n",
    "\n",
    "Going along with this behaviour, the <code>predict_one</code> method initially returns None because the model hasn't seen any labelled data yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "107832ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import tree\n",
    "\n",
    "data_stream = iter(dataset)\n",
    "sample, target = next(data_stream)\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier()\n",
    "print(model.predict_proba_one(sample))\n",
    "print(model.predict_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45f2c4",
   "metadata": {},
   "source": [
    "However, when the model learns examples, it adds those classes to the possibilities of the model. For example, learning the first sample will give 100% of probabilities that the sample is assigned to that class. In fact, there are not more options since only one class sample was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6931677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'path'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">path\n",
       "</pre>\n"
      ],
      "text/plain": [
       "path\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.learn_one(sample, target)\n",
    "print(model.predict_proba_one(sample))\n",
    "print(model.predict_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa28b04",
   "metadata": {},
   "source": [
    "If a second sample is used to train, we can see how the probabilies change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e91e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'foliage'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'foliage'\u001b[0m: \u001b[1;36m0.5\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[1;36m0.5\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">foliage\n",
       "</pre>\n"
      ],
      "text/plain": [
       "foliage\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample, target = next(data_stream) # Next sample on the list\n",
    "\n",
    "model.learn_one(sample, target)\n",
    "print(model.predict_proba_one(sample))\n",
    "print(model.predict_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3517c",
   "metadata": {},
   "source": [
    "This is one of the key points of online classifiers, the models can deal with new classes which appear in the data stream.\n",
    "\n",
    "Typically, the data is used once to make a prediction. When the prediction is made, the ground-truth will emerge later and it can be used first to train the model and also to evaluate. This schema is usually called **progressive validation**. Once the model is evaluated, the same observation is used to adjust the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd262130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">            Precision   Recall   F1       Support  \n",
       "                                                   \n",
       "brickface      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.13</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84.85</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.81</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "   cement      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78.92</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83.94</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81.35</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "  foliage      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.69</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.30</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.02</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "    grass     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.00</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96.97</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.46</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "     path      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.63</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91.19</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.91</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">329</span>  \n",
       "      sky      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.08</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.18</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.63</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "   window      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.50</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67.88</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53.02</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "                                                   \n",
       "    Macro      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.28</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.62</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.31</span>%            \n",
       "    Micro      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%            \n",
       " Weighted      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.27</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.31</span>%            \n",
       "\n",
       "                  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>% accuracy                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "            Precision   Recall   F1       Support  \n",
       "                                                   \n",
       "brickface      \u001b[1;36m77.13\u001b[0m%   \u001b[1;36m84.85\u001b[0m%   \u001b[1;36m80.81\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "   cement      \u001b[1;36m78.92\u001b[0m%   \u001b[1;36m83.94\u001b[0m%   \u001b[1;36m81.35\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "  foliage      \u001b[1;36m65.69\u001b[0m%   \u001b[1;36m20.30\u001b[0m%   \u001b[1;36m31.02\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "    grass     \u001b[1;36m100.00\u001b[0m%   \u001b[1;36m96.97\u001b[0m%   \u001b[1;36m98.46\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "     path      \u001b[1;36m90.63\u001b[0m%   \u001b[1;36m91.19\u001b[0m%   \u001b[1;36m90.91\u001b[0m%       \u001b[1;36m329\u001b[0m  \n",
       "      sky      \u001b[1;36m99.08\u001b[0m%   \u001b[1;36m98.18\u001b[0m%   \u001b[1;36m98.63\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "   window      \u001b[1;36m43.50\u001b[0m%   \u001b[1;36m67.88\u001b[0m%   \u001b[1;36m53.02\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "                                                   \n",
       "    Macro      \u001b[1;36m79.28\u001b[0m%   \u001b[1;36m77.62\u001b[0m%   \u001b[1;36m76.31\u001b[0m%            \n",
       "    Micro      \u001b[1;36m77.61\u001b[0m%   \u001b[1;36m77.61\u001b[0m%   \u001b[1;36m77.61\u001b[0m%            \n",
       " Weighted      \u001b[1;36m79.27\u001b[0m%   \u001b[1;36m77.61\u001b[0m%   \u001b[1;36m76.31\u001b[0m%            \n",
       "\n",
       "                  \u001b[1;36m77.61\u001b[0m% accuracy                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.ClassificationReport()\n",
    "\n",
    "for sample, target in dataset:\n",
    "    prediction = model.predict_one(sample)\n",
    "    if prediction is not None:\n",
    "        metric.update(target, prediction)\n",
    "    model.learn_one(sample, target)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1f532",
   "metadata": {},
   "source": [
    "In this case, [ClassificationReport](https://riverml.xyz/0.14.0/api/metrics/ClassificationReport/) retrieves the precision, recall and F1 for each class the model has seen. Additionally, the Support column indicates the number of instances identified in the stream. Finally, we can see the three different aggregated measures and the general accuracy of the system. \n",
    "\n",
    "This exemplifies a typical pipeline in stream learning. It is so frequent that  River has a class to encapsulate the whole process in a single instance, as in the binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14dae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">            Precision   Recall   F1       Support  \n",
       "                                                   \n",
       "brickface      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.13</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84.85</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.81</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "   cement      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78.92</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83.94</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81.35</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "  foliage      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.69</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.30</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.02</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "    grass     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.00</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96.97</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.46</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "     path      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.63</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91.19</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90.91</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">329</span>  \n",
       "      sky      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.08</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.18</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.63</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "   window      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.50</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67.88</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53.02</span>%        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>  \n",
       "                                                   \n",
       "    Macro      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.28</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.62</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.31</span>%            \n",
       "    Micro      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%            \n",
       " Weighted      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.27</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>%   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76.31</span>%            \n",
       "\n",
       "                  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.61</span>% accuracy                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "            Precision   Recall   F1       Support  \n",
       "                                                   \n",
       "brickface      \u001b[1;36m77.13\u001b[0m%   \u001b[1;36m84.85\u001b[0m%   \u001b[1;36m80.81\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "   cement      \u001b[1;36m78.92\u001b[0m%   \u001b[1;36m83.94\u001b[0m%   \u001b[1;36m81.35\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "  foliage      \u001b[1;36m65.69\u001b[0m%   \u001b[1;36m20.30\u001b[0m%   \u001b[1;36m31.02\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "    grass     \u001b[1;36m100.00\u001b[0m%   \u001b[1;36m96.97\u001b[0m%   \u001b[1;36m98.46\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "     path      \u001b[1;36m90.63\u001b[0m%   \u001b[1;36m91.19\u001b[0m%   \u001b[1;36m90.91\u001b[0m%       \u001b[1;36m329\u001b[0m  \n",
       "      sky      \u001b[1;36m99.08\u001b[0m%   \u001b[1;36m98.18\u001b[0m%   \u001b[1;36m98.63\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "   window      \u001b[1;36m43.50\u001b[0m%   \u001b[1;36m67.88\u001b[0m%   \u001b[1;36m53.02\u001b[0m%        \u001b[1;36m33\u001b[0m  \n",
       "                                                   \n",
       "    Macro      \u001b[1;36m79.28\u001b[0m%   \u001b[1;36m77.62\u001b[0m%   \u001b[1;36m76.31\u001b[0m%            \n",
       "    Micro      \u001b[1;36m77.61\u001b[0m%   \u001b[1;36m77.61\u001b[0m%   \u001b[1;36m77.61\u001b[0m%            \n",
       " Weighted      \u001b[1;36m79.27\u001b[0m%   \u001b[1;36m77.61\u001b[0m%   \u001b[1;36m76.31\u001b[0m%            \n",
       "\n",
       "                  \u001b[1;36m77.61\u001b[0m% accuracy                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import evaluate\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier()\n",
    "metric = metrics.ClassificationReport()\n",
    "\n",
    "print(evaluate.progressive_val_score(dataset, model, metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd8ee2",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Lastly, about the typical ML problems, we have the regression ones. In this case, the model has to predict a numeric output for a given sample. A  regression sample is made up of a bunch of features and a target which is usually codified as a continuous number, although it may also be discrete. Let's see an example with the Trump approval rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ff884e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Donald Trump approval ratings.\n",
       "\n",
       "This dataset was obtained by reshaping the data used by FiveThirtyEight for analyzing Donald\n",
       "Trump's approval ratings. It contains <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> features, which are approval ratings collected by\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> polling agencies. The target is the approval rating from FiveThirtyEight's model. The goal of\n",
       "this task is to see if we can reproduce FiveThirtyEight's model.\n",
       "\n",
       "    Name  TrumpApproval                                                                                            \n",
       "    Task  Regression                                                                                               \n",
       " Samples  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">001</span>                                                                                                    \n",
       "Features  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>                                                                                                        \n",
       "  Sparse  <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                                                                                                    \n",
       "    Path  <span style=\"color: #800080; text-decoration-color: #800080\">/home/david/software/miniconda3/envs/ml2/lib/python3.8/site-packages/river/datasets/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">trump_approval.csv.gz</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Donald Trump approval ratings.\n",
       "\n",
       "This dataset was obtained by reshaping the data used by FiveThirtyEight for analyzing Donald\n",
       "Trump's approval ratings. It contains \u001b[1;36m5\u001b[0m features, which are approval ratings collected by\n",
       "\u001b[1;36m5\u001b[0m polling agencies. The target is the approval rating from FiveThirtyEight's model. The goal of\n",
       "this task is to see if we can reproduce FiveThirtyEight's model.\n",
       "\n",
       "    Name  TrumpApproval                                                                                            \n",
       "    Task  Regression                                                                                               \n",
       " Samples  \u001b[1;36m1\u001b[0m,\u001b[1;36m001\u001b[0m                                                                                                    \n",
       "Features  \u001b[1;36m6\u001b[0m                                                                                                        \n",
       "  Sparse  \u001b[3;91mFalse\u001b[0m                                                                                                    \n",
       "    Path  \u001b[35m/home/david/software/miniconda3/envs/ml2/lib/python3.8/site-packages/river/datasets/\u001b[0m\u001b[95mtrump_approval.csv.gz\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = datasets.TrumpApproval()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d757d",
   "metadata": {},
   "source": [
    "So, we have a dataset with 6 features and we have to give a prediction in $[0,1]$. To do so, we are going to use a regression model, in this case, an adapted [KNN](https://riverml.xyz/0.14.0/api/neighbors/KNNRegressor/) to perform regression which is already implemented in the library.\n",
    "\n",
    "It must be noted that the regression models do not have the <code>predict_proba_one()</code> method since it does not calculate class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1377fca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import neighbors\n",
    "\n",
    "data_stream = iter(dataset)\n",
    "sample, target = next(data_stream)\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "print(model.predict_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3c6d2",
   "metadata": {},
   "source": [
    "As it can be seen, the model has not been trained already and, therefore, the default output is $0.0$. Now, we are going to train the model and repeat the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "526d8b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.75505</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m43.75505\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.learn_one(sample, target)\n",
    "print(model.predict_one(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f355c53",
   "metadata": {},
   "source": [
    "Going along with the **progressive validation** as in the previous cases, we can found the same loop of prediction, evaluation and train that we have previously seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "373e6cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MAE: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.31039</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MAE: \u001b[1;36m0.31039\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "\n",
    "metric = metrics.MAE()\n",
    "\n",
    "for sample, target in dataset:\n",
    "    prediction = model.predict_one(sample)\n",
    "    metric.update(target, prediction)\n",
    "    model.learn_one(sample, target)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339df89d",
   "metadata": {},
   "source": [
    "Or, in the compact notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eff963d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE: 0.31039"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import evaluate\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "metric = metrics.MAE()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
